{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark DataFrame Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the PySpark session\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "# Encoding categorical data\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import functions as f\n",
    "# PySpark Data Types\n",
    "from pyspark.sql.types import *\n",
    "# Add DataFrame columns from Python lists,\n",
    "# and other PySpark Aggregate Functions\n",
    "from pyspark.sql.functions import (\n",
    "    array,\n",
    "    col,\n",
    "    mean,\n",
    "    min,\n",
    "    max,\n",
    ")\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql import types as t\n",
    "# Creating pyspark literals\n",
    "from pyspark.sql.functions import lit\n",
    "# Creating PySpark Columns\n",
    "from pyspark.sql.column import Column\n",
    "# Numpy Array functions\n",
    "import numpy as np\n",
    "# Helper functions\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the PySpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make Pyspark Dataframe from titanic csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('titanic.csv',header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the First 5 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the original assignment in DS 1.1:*\n",
    "\n",
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of Age values are empty (or null)?\n",
    "\n",
    "For this question, I used values provided by table in the `df.describe.show()` cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in the Age column: 177.\n"
     ]
    }
   ],
   "source": [
    "num_rows_overall = 891\n",
    "num_values_in_age = 714\n",
    "num_null_in_age = num_rows_overall - num_values_in_age\n",
    "print(f'The number of null values in the Age column: {num_null_in_age}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column as gender, when Sex is female it is zero when sex is male it is one\n",
    "\n",
    "Background info on how the next two cells work can be found on [this blog post](https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08), credit to the author Rahul Agarwal for how User-Defined Functions work in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_binary_gender(sex):\n",
    "    '''Return 0 for female and 1 for male.'''\n",
    "    if sex == 'male':\n",
    "        return 1\n",
    "    # all non-males will be 0\n",
    "    return 0\n",
    "        \n",
    "# convert determine_binary_gender to a UDF Function \n",
    "udf_determine_binary_gender = F.udf(determine_binary_gender, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     1|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|     0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|     0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|     0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     1|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|     1|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     1|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|     1|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|     0|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|     0|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|     0|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|     0|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     1|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|     1|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|     0|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|     0|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|     1|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|     1|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|     0|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|     0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add the new column to the DataFrame\n",
    "df = df.withColumn(\"Gender\", udf_determine_binary_gender(\"Sex\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Shape of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 13)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all of the Ages that are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab ages column, by getting underlying RDD\n",
    "ages = df.rdd.map(lambda r: r.Age).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0\n",
      "38.0\n",
      "26.0\n",
      "35.0\n",
      "35.0\n",
      "54.0\n",
      "2.0\n",
      "27.0\n",
      "14.0\n",
      "4.0\n",
      "58.0\n",
      "20.0\n",
      "39.0\n",
      "14.0\n",
      "55.0\n",
      "2.0\n",
      "31.0\n",
      "35.0\n",
      "34.0\n",
      "15.0\n",
      "28.0\n",
      "8.0\n",
      "38.0\n",
      "19.0\n",
      "40.0\n",
      "66.0\n",
      "28.0\n",
      "42.0\n",
      "21.0\n",
      "18.0\n",
      "14.0\n",
      "40.0\n",
      "27.0\n",
      "3.0\n",
      "19.0\n",
      "18.0\n",
      "7.0\n",
      "21.0\n",
      "49.0\n",
      "29.0\n",
      "65.0\n",
      "21.0\n",
      "28.5\n",
      "5.0\n",
      "11.0\n",
      "22.0\n",
      "38.0\n",
      "45.0\n",
      "4.0\n",
      "29.0\n",
      "19.0\n",
      "17.0\n",
      "26.0\n",
      "32.0\n",
      "16.0\n",
      "21.0\n",
      "26.0\n",
      "32.0\n",
      "25.0\n",
      "0.83\n",
      "30.0\n",
      "22.0\n",
      "29.0\n",
      "28.0\n",
      "17.0\n",
      "33.0\n",
      "16.0\n",
      "23.0\n",
      "24.0\n",
      "29.0\n",
      "20.0\n",
      "46.0\n",
      "26.0\n",
      "59.0\n",
      "71.0\n",
      "23.0\n",
      "34.0\n",
      "34.0\n",
      "28.0\n",
      "21.0\n",
      "33.0\n",
      "37.0\n",
      "28.0\n",
      "21.0\n",
      "38.0\n",
      "47.0\n",
      "14.5\n",
      "22.0\n",
      "20.0\n",
      "17.0\n",
      "21.0\n",
      "70.5\n",
      "29.0\n",
      "24.0\n",
      "2.0\n",
      "21.0\n",
      "32.5\n",
      "32.5\n",
      "54.0\n",
      "12.0\n",
      "24.0\n",
      "45.0\n",
      "33.0\n",
      "20.0\n",
      "47.0\n",
      "29.0\n",
      "25.0\n",
      "23.0\n",
      "19.0\n",
      "37.0\n",
      "16.0\n",
      "24.0\n",
      "22.0\n",
      "24.0\n",
      "19.0\n",
      "18.0\n",
      "19.0\n",
      "27.0\n",
      "9.0\n",
      "36.5\n",
      "42.0\n",
      "51.0\n",
      "22.0\n",
      "55.5\n",
      "40.5\n",
      "51.0\n",
      "16.0\n",
      "30.0\n",
      "44.0\n",
      "40.0\n",
      "26.0\n",
      "17.0\n",
      "1.0\n",
      "9.0\n",
      "45.0\n",
      "28.0\n",
      "61.0\n",
      "4.0\n",
      "1.0\n",
      "21.0\n",
      "56.0\n",
      "18.0\n",
      "50.0\n",
      "30.0\n",
      "36.0\n",
      "9.0\n",
      "1.0\n",
      "4.0\n",
      "45.0\n",
      "40.0\n",
      "36.0\n",
      "32.0\n",
      "19.0\n",
      "19.0\n",
      "3.0\n",
      "44.0\n",
      "58.0\n",
      "42.0\n",
      "24.0\n",
      "28.0\n",
      "34.0\n",
      "45.5\n",
      "18.0\n",
      "2.0\n",
      "32.0\n",
      "26.0\n",
      "16.0\n",
      "40.0\n",
      "24.0\n",
      "35.0\n",
      "22.0\n",
      "30.0\n",
      "31.0\n",
      "27.0\n",
      "42.0\n",
      "32.0\n",
      "30.0\n",
      "16.0\n",
      "27.0\n",
      "51.0\n",
      "38.0\n",
      "22.0\n",
      "19.0\n",
      "20.5\n",
      "18.0\n",
      "35.0\n",
      "29.0\n",
      "59.0\n",
      "5.0\n",
      "24.0\n",
      "44.0\n",
      "8.0\n",
      "19.0\n",
      "33.0\n",
      "29.0\n",
      "22.0\n",
      "30.0\n",
      "44.0\n",
      "25.0\n",
      "24.0\n",
      "37.0\n",
      "54.0\n",
      "29.0\n",
      "62.0\n",
      "30.0\n",
      "41.0\n",
      "29.0\n",
      "30.0\n",
      "35.0\n",
      "50.0\n",
      "3.0\n",
      "52.0\n",
      "40.0\n",
      "36.0\n",
      "16.0\n",
      "25.0\n",
      "58.0\n",
      "35.0\n",
      "25.0\n",
      "41.0\n",
      "37.0\n",
      "63.0\n",
      "45.0\n",
      "7.0\n",
      "35.0\n",
      "65.0\n",
      "28.0\n",
      "16.0\n",
      "19.0\n",
      "33.0\n",
      "30.0\n",
      "22.0\n",
      "42.0\n",
      "22.0\n",
      "26.0\n",
      "19.0\n",
      "36.0\n",
      "24.0\n",
      "24.0\n",
      "23.5\n",
      "2.0\n",
      "50.0\n",
      "19.0\n",
      "0.92\n",
      "17.0\n",
      "30.0\n",
      "30.0\n",
      "24.0\n",
      "18.0\n",
      "26.0\n",
      "28.0\n",
      "43.0\n",
      "26.0\n",
      "24.0\n",
      "54.0\n",
      "31.0\n",
      "40.0\n",
      "22.0\n",
      "27.0\n",
      "30.0\n",
      "22.0\n",
      "36.0\n",
      "61.0\n",
      "36.0\n",
      "31.0\n",
      "16.0\n",
      "45.5\n",
      "38.0\n",
      "16.0\n",
      "29.0\n",
      "41.0\n",
      "45.0\n",
      "45.0\n",
      "2.0\n",
      "24.0\n",
      "28.0\n",
      "25.0\n",
      "36.0\n",
      "24.0\n",
      "40.0\n",
      "3.0\n",
      "42.0\n",
      "23.0\n",
      "15.0\n",
      "25.0\n",
      "28.0\n",
      "22.0\n",
      "38.0\n",
      "40.0\n",
      "29.0\n",
      "45.0\n",
      "35.0\n",
      "30.0\n",
      "60.0\n",
      "24.0\n",
      "25.0\n",
      "18.0\n",
      "19.0\n",
      "22.0\n",
      "3.0\n",
      "22.0\n",
      "27.0\n",
      "20.0\n",
      "19.0\n",
      "42.0\n",
      "1.0\n",
      "32.0\n",
      "35.0\n",
      "18.0\n",
      "1.0\n",
      "36.0\n",
      "17.0\n",
      "36.0\n",
      "21.0\n",
      "28.0\n",
      "23.0\n",
      "24.0\n",
      "22.0\n",
      "31.0\n",
      "46.0\n",
      "23.0\n",
      "28.0\n",
      "39.0\n",
      "26.0\n",
      "21.0\n",
      "28.0\n",
      "20.0\n",
      "34.0\n",
      "51.0\n",
      "3.0\n",
      "21.0\n",
      "33.0\n",
      "44.0\n",
      "34.0\n",
      "18.0\n",
      "30.0\n",
      "10.0\n",
      "21.0\n",
      "29.0\n",
      "28.0\n",
      "18.0\n",
      "28.0\n",
      "19.0\n",
      "32.0\n",
      "28.0\n",
      "42.0\n",
      "17.0\n",
      "50.0\n",
      "14.0\n",
      "21.0\n",
      "24.0\n",
      "64.0\n",
      "31.0\n",
      "45.0\n",
      "20.0\n",
      "25.0\n",
      "28.0\n",
      "4.0\n",
      "13.0\n",
      "34.0\n",
      "5.0\n",
      "52.0\n",
      "36.0\n",
      "30.0\n",
      "49.0\n",
      "29.0\n",
      "65.0\n",
      "50.0\n",
      "48.0\n",
      "34.0\n",
      "47.0\n",
      "48.0\n",
      "38.0\n",
      "56.0\n",
      "0.75\n",
      "38.0\n",
      "33.0\n",
      "23.0\n",
      "22.0\n",
      "34.0\n",
      "29.0\n",
      "22.0\n",
      "2.0\n",
      "9.0\n",
      "50.0\n",
      "63.0\n",
      "25.0\n",
      "35.0\n",
      "58.0\n",
      "30.0\n",
      "9.0\n",
      "21.0\n",
      "55.0\n",
      "71.0\n",
      "21.0\n",
      "54.0\n",
      "25.0\n",
      "24.0\n",
      "17.0\n",
      "21.0\n",
      "37.0\n",
      "16.0\n",
      "18.0\n",
      "33.0\n",
      "28.0\n",
      "26.0\n",
      "29.0\n",
      "36.0\n",
      "54.0\n",
      "24.0\n",
      "47.0\n",
      "34.0\n",
      "36.0\n",
      "32.0\n",
      "30.0\n",
      "22.0\n",
      "44.0\n",
      "40.5\n",
      "50.0\n",
      "39.0\n",
      "23.0\n",
      "2.0\n",
      "17.0\n",
      "30.0\n",
      "7.0\n",
      "45.0\n",
      "30.0\n",
      "22.0\n",
      "36.0\n",
      "9.0\n",
      "11.0\n",
      "32.0\n",
      "50.0\n",
      "64.0\n",
      "19.0\n",
      "33.0\n",
      "8.0\n",
      "17.0\n",
      "27.0\n",
      "22.0\n",
      "22.0\n",
      "62.0\n",
      "48.0\n",
      "39.0\n",
      "36.0\n",
      "40.0\n",
      "28.0\n",
      "24.0\n",
      "19.0\n",
      "29.0\n",
      "32.0\n",
      "62.0\n",
      "53.0\n",
      "36.0\n",
      "16.0\n",
      "19.0\n",
      "34.0\n",
      "39.0\n",
      "32.0\n",
      "25.0\n",
      "39.0\n",
      "54.0\n",
      "36.0\n",
      "18.0\n",
      "47.0\n",
      "60.0\n",
      "22.0\n",
      "35.0\n",
      "52.0\n",
      "47.0\n",
      "37.0\n",
      "36.0\n",
      "49.0\n",
      "49.0\n",
      "24.0\n",
      "44.0\n",
      "35.0\n",
      "36.0\n",
      "30.0\n",
      "27.0\n",
      "22.0\n",
      "40.0\n",
      "39.0\n",
      "35.0\n",
      "24.0\n",
      "34.0\n",
      "26.0\n",
      "4.0\n",
      "26.0\n",
      "27.0\n",
      "42.0\n",
      "20.0\n",
      "21.0\n",
      "21.0\n",
      "61.0\n",
      "57.0\n",
      "21.0\n",
      "26.0\n",
      "80.0\n",
      "51.0\n",
      "32.0\n",
      "9.0\n",
      "28.0\n",
      "32.0\n",
      "31.0\n",
      "41.0\n",
      "20.0\n",
      "24.0\n",
      "2.0\n",
      "0.75\n",
      "48.0\n",
      "19.0\n",
      "56.0\n",
      "23.0\n",
      "18.0\n",
      "21.0\n",
      "18.0\n",
      "24.0\n",
      "32.0\n",
      "23.0\n",
      "58.0\n",
      "50.0\n",
      "40.0\n",
      "47.0\n",
      "36.0\n",
      "20.0\n",
      "32.0\n",
      "25.0\n",
      "43.0\n",
      "40.0\n",
      "31.0\n",
      "70.0\n",
      "31.0\n",
      "18.0\n",
      "24.5\n",
      "18.0\n",
      "43.0\n",
      "36.0\n",
      "27.0\n",
      "20.0\n",
      "14.0\n",
      "60.0\n",
      "25.0\n",
      "14.0\n",
      "19.0\n",
      "18.0\n",
      "15.0\n",
      "31.0\n",
      "4.0\n",
      "25.0\n",
      "60.0\n",
      "52.0\n",
      "44.0\n",
      "49.0\n",
      "42.0\n",
      "18.0\n",
      "35.0\n",
      "18.0\n",
      "25.0\n",
      "26.0\n",
      "39.0\n",
      "45.0\n",
      "42.0\n",
      "22.0\n",
      "24.0\n",
      "48.0\n",
      "29.0\n",
      "52.0\n",
      "19.0\n",
      "38.0\n",
      "27.0\n",
      "33.0\n",
      "6.0\n",
      "17.0\n",
      "34.0\n",
      "50.0\n",
      "27.0\n",
      "20.0\n",
      "30.0\n",
      "25.0\n",
      "25.0\n",
      "29.0\n",
      "11.0\n",
      "23.0\n",
      "23.0\n",
      "28.5\n",
      "48.0\n",
      "35.0\n",
      "36.0\n",
      "21.0\n",
      "24.0\n",
      "31.0\n",
      "70.0\n",
      "16.0\n",
      "30.0\n",
      "19.0\n",
      "31.0\n",
      "4.0\n",
      "6.0\n",
      "33.0\n",
      "23.0\n",
      "48.0\n",
      "0.67\n",
      "28.0\n",
      "18.0\n",
      "34.0\n",
      "33.0\n",
      "41.0\n",
      "20.0\n",
      "36.0\n",
      "16.0\n",
      "51.0\n",
      "30.5\n",
      "32.0\n",
      "24.0\n",
      "48.0\n",
      "57.0\n",
      "54.0\n",
      "18.0\n",
      "5.0\n",
      "43.0\n",
      "13.0\n",
      "17.0\n",
      "29.0\n",
      "25.0\n",
      "25.0\n",
      "18.0\n",
      "8.0\n",
      "1.0\n",
      "46.0\n",
      "16.0\n",
      "25.0\n",
      "39.0\n",
      "49.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "34.0\n",
      "31.0\n",
      "11.0\n",
      "0.42\n",
      "27.0\n",
      "31.0\n",
      "39.0\n",
      "18.0\n",
      "39.0\n",
      "33.0\n",
      "26.0\n",
      "39.0\n",
      "35.0\n",
      "6.0\n",
      "30.5\n",
      "23.0\n",
      "31.0\n",
      "43.0\n",
      "10.0\n",
      "52.0\n",
      "27.0\n",
      "38.0\n",
      "27.0\n",
      "2.0\n",
      "1.0\n",
      "62.0\n",
      "15.0\n",
      "0.83\n",
      "23.0\n",
      "18.0\n",
      "39.0\n",
      "21.0\n",
      "32.0\n",
      "20.0\n",
      "16.0\n",
      "30.0\n",
      "34.5\n",
      "17.0\n",
      "42.0\n",
      "35.0\n",
      "28.0\n",
      "4.0\n",
      "74.0\n",
      "9.0\n",
      "16.0\n",
      "44.0\n",
      "18.0\n",
      "45.0\n",
      "51.0\n",
      "24.0\n",
      "41.0\n",
      "21.0\n",
      "48.0\n",
      "24.0\n",
      "42.0\n",
      "27.0\n",
      "31.0\n",
      "4.0\n",
      "26.0\n",
      "47.0\n",
      "33.0\n",
      "47.0\n",
      "28.0\n",
      "15.0\n",
      "20.0\n",
      "19.0\n",
      "56.0\n",
      "25.0\n",
      "33.0\n",
      "22.0\n",
      "28.0\n",
      "25.0\n",
      "39.0\n",
      "27.0\n",
      "19.0\n",
      "26.0\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "# print all integer values\n",
    "for age in ages:\n",
    "    if age is not None:\n",
    "        print(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the dataframe for those whose Embarked section was 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|       Ticket|    Fare|Cabin|Embarked|Gender|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|     PC 17599| 71.2833|  C85|       C|     0|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|       237736| 30.0708| null|       C|     0|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|         2649|   7.225| null|       C|     0|\n",
      "|         27|       0|     3|Emir, Mr. Farred ...|  male|null|    0|    0|         2631|   7.225| null|       C|     1|\n",
      "|         31|       0|     1|Uruchurtu, Don. M...|  male|40.0|    0|    0|     PC 17601| 27.7208| null|       C|     1|\n",
      "|         32|       1|     1|Spencer, Mrs. Wil...|female|null|    1|    0|     PC 17569|146.5208|  B78|       C|     0|\n",
      "|         35|       0|     1|Meyer, Mr. Edgar ...|  male|28.0|    1|    0|     PC 17604| 82.1708| null|       C|     1|\n",
      "|         37|       1|     3|    Mamee, Mr. Hanna|  male|null|    0|    0|         2677|  7.2292| null|       C|     1|\n",
      "|         40|       1|     3|Nicola-Yarred, Mi...|female|14.0|    1|    0|         2651| 11.2417| null|       C|     0|\n",
      "|         43|       0|     3| Kraeff, Mr. Theodor|  male|null|    0|    0|       349253|  7.8958| null|       C|     1|\n",
      "|         44|       1|     2|Laroche, Miss. Si...|female| 3.0|    1|    2|SC/Paris 2123| 41.5792| null|       C|     0|\n",
      "|         49|       0|     3| Samaan, Mr. Youssef|  male|null|    2|    0|         2662| 21.6792| null|       C|     1|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|     PC 17572| 76.7292|  D33|       C|     0|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|       113509| 61.9792|  B30|       C|     1|\n",
      "|         58|       0|     3| Novel, Mr. Mansouer|  male|28.5|    0|    0|         2697|  7.2292| null|       C|     1|\n",
      "|         61|       0|     3|Sirayanian, Mr. O...|  male|22.0|    0|    0|         2669|  7.2292| null|       C|     1|\n",
      "|         65|       0|     1|Stewart, Mr. Albe...|  male|null|    0|    0|     PC 17605| 27.7208| null|       C|     1|\n",
      "|         66|       1|     3|Moubarek, Master....|  male|null|    1|    1|         2661| 15.2458| null|       C|     1|\n",
      "|         74|       0|     3|Chronopoulos, Mr....|  male|26.0|    1|    0|         2680| 14.4542| null|       C|     1|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|     PC 17754| 34.6542|   A5|       C|     1|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Embarked == 'C').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe a specific column \n",
    "\n",
    "I used 'Embarked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|Embarked|\n",
      "+-------+--------+\n",
      "|  count|     889|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|       C|\n",
      "|    max|       S|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Embarked').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many unique values does the 'Embarked' have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 unique values in the 'Embarked' column.\n"
     ]
    }
   ],
   "source": [
    "# get the unique values from the column\n",
    "unique = df.select('Embarked').distinct()\n",
    "# unwrap the Row objects\n",
    "unique_values = unique.rdd.map(lambda r: r.Embarked).collect()\n",
    "# count the number of values, NULL should be excluded\n",
    "nunique = len([val for val in unique_values if val is not None])\n",
    "print(f\"There are {nunique} unique values in the 'Embarked' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the Counts for Each Unique Value in 'Embarked'\n",
    "\n",
    "AKA, do the PySpark version of Pandas' `value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|    2|\n",
      "|       C|   65|\n",
      "|       S|  116|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping NaN values\n",
    "df = df.dropna()\n",
    "# showing the frequency distribution for the Embarked column\n",
    "df.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df.groupBy('Embarked').count()\n",
    "value_counts.write.json('Embarked_Col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average Age for female and male (based on sex) for those who have 'Embarked' on section 'C'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_age(sex):\n",
    "    '''Returns the average age of men or women, whom Embarked from section C.'''\n",
    "    ages = util.get_ages(df, sex)\n",
    "    # return the mean of the ages\n",
    "    return np.mean(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average age for men who embarked from 'C' section: 39.8 years.\n"
     ]
    }
   ],
   "source": [
    "# average age for men\n",
    "men_avg = round(average_age('male'), 1)\n",
    "print(f\"The average age for men who embarked from 'C' section: {men_avg} years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average age for women who embarked from 'C' section: 35.4 years.\n"
     ]
    }
   ],
   "source": [
    "# average age for women\n",
    "women_avg = round(average_age('female'), 1)\n",
    "print(f\"The average age for women who embarked from 'C' section: {women_avg} years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Age is the oldest for female and male (based on sex) for those who have 'Embarked' on section 'C'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oldest age amongst the men who embarked from the 'C' section: 71.0 years.\n"
     ]
    }
   ],
   "source": [
    "def get_max_age(sex):\n",
    "    '''Return the max age for men or women '''\n",
    "    ages = util.get_ages(df, sex)\n",
    "    # return the max value\n",
    "    return np.max(ages)\n",
    "\n",
    "# display the max value for men\n",
    "max_men = get_max_age('male')\n",
    "print(\n",
    "        \"The oldest age amongst the men \" +\n",
    "        \"who embarked from the 'C' section: \" +\n",
    "        f\"{max_men} years.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oldest age amongst the women who embarked from the 'C' section: 60.0 years.\n"
     ]
    }
   ],
   "source": [
    "# display the max value for women\n",
    "max_women = get_max_age('female')\n",
    "print(\n",
    "        \"The oldest age amongst the women \" +\n",
    "        \"who embarked from the 'C' section: \" +\n",
    "        f\"{max_women} years.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the number of female and male at each Passenger Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 84 men and 74 women in Passenger class 1.\n",
      "There were 5 men and 5 women in Passenger class 3.\n",
      "There were 6 men and 9 women in Passenger class 2.\n"
     ]
    }
   ],
   "source": [
    "def numbers_of_male_female(passenger_class, sex):\n",
    "    '''Return the numbers of male and female, for a given passenger class.'''\n",
    "    num_people = df.filter((df.Pclass == passenger_class) & (df.Sex == sex)).rdd.map(lambda person: person.Age).collect()\n",
    "    return len(num_people)\n",
    "\n",
    "# get a list of all passenger classes, as a list\n",
    "unique_classes = df.select('Pclass').distinct().rdd.map(lambda person: person.Pclass).collect()\n",
    "# iterate over the classes\n",
    "for p_class in unique_classes:\n",
    "    # get the numbers of men and women\n",
    "    num_male = numbers_of_male_female(p_class, 'male')\n",
    "    num_female = numbers_of_male_female(p_class, 'female')\n",
    "    # print both\n",
    "    print(f\"There were {num_male} men and {num_female} women in Passenger class {p_class}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percent of passengers embarked at C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.5% for passengers embarked at C.\n"
     ]
    }
   ],
   "source": [
    "num_c_passengers = len(\n",
    "    df.filter(df.Embarked == 'C').rdd.collect()\n",
    ")\n",
    "\n",
    "percentage = round(num_c_passengers / df.count(), 3) * 100\n",
    "print(f\"{percentage}% for passengers embarked at C.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percent of female passengers embarked at C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.6% for female passengers embarked at C.\n"
     ]
    }
   ],
   "source": [
    "# the function gets the ages of female passengers who embarked from C,\n",
    "# and then we also take the length\n",
    "num_females_at_c = len(util.get_ages(df, 'female')) \n",
    "# get the total number of female passengers\n",
    "num_females = len(df.filter(df.Sex == 'female').rdd.collect())\n",
    "# compute and display the percentage\n",
    "percentage = round(num_females_at_c / num_females , 3) * 100\n",
    "print(f\"{percentage}% for female passengers embarked at C.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds23_env",
   "language": "python",
   "name": "ds23_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
